{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bước vào trận đấu, Barcelona nhanh chóng tràn ...</td>\n",
       "      <td>La Liga,Sevilla,Olimpic Lluis Companys,Lewando...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Willian đi vào lịch sử bóng đá xứ samba. Với 1...</td>\n",
       "      <td>Estevao Willian,Neymar,giải VĐQG Brazil,Serie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Giải vô địch ná cao su thế giới năm 2024 đã di...</td>\n",
       "      <td>ná cao su,giải vô địch,giải Ba,Thượng Hải,vận ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giải đấu khởi tranh từ ngày 13/10 đến ngày 20/...</td>\n",
       "      <td>Trảng Bàng,thiếu niên,thị xã,cao thượng,Gia Lộ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giải vô địch Karate quốc gia lần thứ 33 năm 20...</td>\n",
       "      <td>Nguyễn Thị Bảo Ngọc,Hoàng Thị Mỹ Tâm,huy chươn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36195</th>\n",
       "      <td>Ngày 16/8, tại Công an tỉnh Thái Bình, Bộ Công...</td>\n",
       "      <td>Trần Xuân Ánh,Công an tỉnh Thái Bình,giữ chức ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36196</th>\n",
       "      <td>(từ ngày 1-10), lực lượng đã kiểm tra, xử phạt...</td>\n",
       "      <td>Trảng Bom,Công an huyện Trảng Bom,xử phạt,THPT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36197</th>\n",
       "      <td>Thủ tướng Trung Quốc Lý Cường đang có chuyến t...</td>\n",
       "      <td>đà phát triển,Lý Cường,đối tác,quan hệ,năm,vốn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36198</th>\n",
       "      <td>Các đoàn xuất quân “Ứng cứu thông tin, khắc ph...</td>\n",
       "      <td>VNPT Bình Dương,Yagi,bão,Bắc Giang,hậu quả,khô...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36199</th>\n",
       "      <td>Nhà chức trách xác định, Hoàng Văn Thảo có hàn...</td>\n",
       "      <td>Hoàng Văn Thảo,chạy án,Cục phó,giả danh,TP Hồ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  \\\n",
       "0      Bước vào trận đấu, Barcelona nhanh chóng tràn ...   \n",
       "1      Willian đi vào lịch sử bóng đá xứ samba. Với 1...   \n",
       "2      Giải vô địch ná cao su thế giới năm 2024 đã di...   \n",
       "3      Giải đấu khởi tranh từ ngày 13/10 đến ngày 20/...   \n",
       "4      Giải vô địch Karate quốc gia lần thứ 33 năm 20...   \n",
       "...                                                  ...   \n",
       "36195  Ngày 16/8, tại Công an tỉnh Thái Bình, Bộ Công...   \n",
       "36196  (từ ngày 1-10), lực lượng đã kiểm tra, xử phạt...   \n",
       "36197  Thủ tướng Trung Quốc Lý Cường đang có chuyến t...   \n",
       "36198  Các đoàn xuất quân “Ứng cứu thông tin, khắc ph...   \n",
       "36199  Nhà chức trách xác định, Hoàng Văn Thảo có hàn...   \n",
       "\n",
       "                                                    tags  \n",
       "0      La Liga,Sevilla,Olimpic Lluis Companys,Lewando...  \n",
       "1      Estevao Willian,Neymar,giải VĐQG Brazil,Serie ...  \n",
       "2      ná cao su,giải vô địch,giải Ba,Thượng Hải,vận ...  \n",
       "3      Trảng Bàng,thiếu niên,thị xã,cao thượng,Gia Lộ...  \n",
       "4      Nguyễn Thị Bảo Ngọc,Hoàng Thị Mỹ Tâm,huy chươn...  \n",
       "...                                                  ...  \n",
       "36195  Trần Xuân Ánh,Công an tỉnh Thái Bình,giữ chức ...  \n",
       "36196  Trảng Bom,Công an huyện Trảng Bom,xử phạt,THPT...  \n",
       "36197  đà phát triển,Lý Cường,đối tác,quan hệ,năm,vốn...  \n",
       "36198  VNPT Bình Dương,Yagi,bão,Bắc Giang,hậu quả,khô...  \n",
       "36199  Hoàng Văn Thảo,chạy án,Cục phó,giả danh,TP Hồ ...  \n",
       "\n",
       "[36200 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(DATA_PATH + \"articles_training_xlm.tsv\", sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bước vào trận đấu, Barcelona nhanh chóng tràn ...</td>\n",
       "      <td>La Liga,Sevilla,Olimpic Lluis Companys,Lewando...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Willian đi vào lịch sử bóng đá xứ samba. Với 1...</td>\n",
       "      <td>Estevao Willian,Neymar,giải VĐQG Brazil,Serie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Giải vô địch ná cao su thế giới năm 2024 đã di...</td>\n",
       "      <td>ná cao su,giải vô địch,giải Ba,Thượng Hải,vận ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Giải đấu khởi tranh từ ngày 13/10 đến ngày 20/...</td>\n",
       "      <td>Trảng Bàng,thiếu niên,thị xã,cao thượng,Gia Lộ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giải vô địch Karate quốc gia lần thứ 33 năm 20...</td>\n",
       "      <td>Nguyễn Thị Bảo Ngọc,Hoàng Thị Mỹ Tâm,huy chươn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36195</th>\n",
       "      <td>Ngày 16/8, tại Công an tỉnh Thái Bình, Bộ Công...</td>\n",
       "      <td>Trần Xuân Ánh,Công an tỉnh Thái Bình,giữ chức ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36196</th>\n",
       "      <td>(từ ngày 1-10), lực lượng đã kiểm tra, xử phạt...</td>\n",
       "      <td>Trảng Bom,Công an huyện Trảng Bom,xử phạt,THPT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36197</th>\n",
       "      <td>Thủ tướng Trung Quốc Lý Cường đang có chuyến t...</td>\n",
       "      <td>đà phát triển,Lý Cường,đối tác,quan hệ,năm,vốn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36198</th>\n",
       "      <td>Các đoàn xuất quân “Ứng cứu thông tin, khắc ph...</td>\n",
       "      <td>VNPT Bình Dương,Yagi,bão,Bắc Giang,hậu quả,khô...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36199</th>\n",
       "      <td>Nhà chức trách xác định, Hoàng Văn Thảo có hàn...</td>\n",
       "      <td>Hoàng Văn Thảo,chạy án,Cục phó,giả danh,TP Hồ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  \\\n",
       "0      Bước vào trận đấu, Barcelona nhanh chóng tràn ...   \n",
       "1      Willian đi vào lịch sử bóng đá xứ samba. Với 1...   \n",
       "2      Giải vô địch ná cao su thế giới năm 2024 đã di...   \n",
       "3      Giải đấu khởi tranh từ ngày 13/10 đến ngày 20/...   \n",
       "4      Giải vô địch Karate quốc gia lần thứ 33 năm 20...   \n",
       "...                                                  ...   \n",
       "36195  Ngày 16/8, tại Công an tỉnh Thái Bình, Bộ Công...   \n",
       "36196  (từ ngày 1-10), lực lượng đã kiểm tra, xử phạt...   \n",
       "36197  Thủ tướng Trung Quốc Lý Cường đang có chuyến t...   \n",
       "36198  Các đoàn xuất quân “Ứng cứu thông tin, khắc ph...   \n",
       "36199  Nhà chức trách xác định, Hoàng Văn Thảo có hàn...   \n",
       "\n",
       "                                                    tags  \n",
       "0      La Liga,Sevilla,Olimpic Lluis Companys,Lewando...  \n",
       "1      Estevao Willian,Neymar,giải VĐQG Brazil,Serie ...  \n",
       "2      ná cao su,giải vô địch,giải Ba,Thượng Hải,vận ...  \n",
       "3      Trảng Bàng,thiếu niên,thị xã,cao thượng,Gia Lộ...  \n",
       "4      Nguyễn Thị Bảo Ngọc,Hoàng Thị Mỹ Tâm,huy chươn...  \n",
       "...                                                  ...  \n",
       "36195  Trần Xuân Ánh,Công an tỉnh Thái Bình,giữ chức ...  \n",
       "36196  Trảng Bom,Công an huyện Trảng Bom,xử phạt,THPT...  \n",
       "36197  đà phát triển,Lý Cường,đối tác,quan hệ,năm,vốn...  \n",
       "36198  VNPT Bình Dương,Yagi,bão,Bắc Giang,hậu quả,khô...  \n",
       "36199  Hoàng Văn Thảo,chạy án,Cục phó,giả danh,TP Hồ ...  \n",
       "\n",
       "[36200 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with no tags\n",
    "df = df.dropna(subset=[\"tags\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMRobertaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"FacebookAI/xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"FacebookAI/xlm-roberta-base\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "print(model.config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁Bước',\n",
       " '▁vào',\n",
       " '▁trận',\n",
       " '▁đấu',\n",
       " ',',\n",
       " '▁Barcelona',\n",
       " '▁nhanh',\n",
       " '▁chóng',\n",
       " '▁tràn',\n",
       " '▁lên',\n",
       " '▁tấn',\n",
       " '▁công',\n",
       " '▁nhưng',\n",
       " '▁v',\n",
       " 'ấ',\n",
       " 'p',\n",
       " '▁phải',\n",
       " '▁sự',\n",
       " '▁kháng',\n",
       " '▁cự',\n",
       " '▁quyết',\n",
       " '▁liệt',\n",
       " '▁của',\n",
       " '▁Sevilla',\n",
       " '.',\n",
       " '▁Bước',\n",
       " '▁ngo',\n",
       " 'ặt',\n",
       " '▁đến',\n",
       " '▁ở',\n",
       " '▁phút',\n",
       " '▁22,',\n",
       " '▁Rap',\n",
       " 'hin',\n",
       " 'ha',\n",
       " '▁bị',\n",
       " '▁phạm',\n",
       " '▁lỗi',\n",
       " '▁trong',\n",
       " '▁vòng',\n",
       " '▁cấm',\n",
       " '▁và',\n",
       " '▁trọng',\n",
       " '▁tài',\n",
       " '▁đã',\n",
       " '▁cho',\n",
       " '▁Barcelona',\n",
       " '▁hưởng',\n",
       " '▁quả',\n",
       " '▁phạt',\n",
       " '▁đề',\n",
       " 'n',\n",
       " '.',\n",
       " '▁Trên',\n",
       " '▁chấm',\n",
       " '▁11',\n",
       " 'm',\n",
       " ',',\n",
       " '▁Le',\n",
       " 'wand',\n",
       " 'owski',\n",
       " '▁đã',\n",
       " '▁ghi',\n",
       " '▁bàn',\n",
       " '▁mở',\n",
       " '▁tỷ',\n",
       " '▁số',\n",
       " '▁cho',\n",
       " '▁Barcelona',\n",
       " '.',\n",
       " '▁Đến',\n",
       " '▁phút',\n",
       " '▁28,',\n",
       " '▁Pedr',\n",
       " 'i',\n",
       " '▁đã',\n",
       " '▁có',\n",
       " '▁bàn',\n",
       " '▁nhân',\n",
       " '▁đôi',\n",
       " '▁cách',\n",
       " '▁biệt',\n",
       " '▁cho',\n",
       " '▁đội',\n",
       " '▁chủ',\n",
       " '▁nhà',\n",
       " '▁trước',\n",
       " '▁khi',\n",
       " '▁Le',\n",
       " 'wand',\n",
       " 'owski',\n",
       " '▁hoàn',\n",
       " '▁tất',\n",
       " '▁cú',\n",
       " '▁đ',\n",
       " 'úp',\n",
       " '▁cho',\n",
       " '▁riêng',\n",
       " '▁mình',\n",
       " '▁ở',\n",
       " '▁phút',\n",
       " '▁39',\n",
       " '.',\n",
       " '▁Hiệp',\n",
       " '▁1',\n",
       " '▁kh',\n",
       " 'ép',\n",
       " '▁lại',\n",
       " '▁với',\n",
       " '▁tỉ',\n",
       " '▁số',\n",
       " '▁3-0',\n",
       " '▁nghiên',\n",
       " 'g',\n",
       " '▁về',\n",
       " '▁Barcelona',\n",
       " '.',\n",
       " '▁Sang',\n",
       " '▁hiệp',\n",
       " '▁2',\n",
       " ',',\n",
       " '▁các',\n",
       " '▁chân',\n",
       " '▁sú',\n",
       " 't',\n",
       " '▁của',\n",
       " '▁Barcelona',\n",
       " '▁liên',\n",
       " '▁tiếp',\n",
       " '▁bắn',\n",
       " '▁phá',\n",
       " '▁khung',\n",
       " '▁thành',\n",
       " '▁của',\n",
       " '▁Sevilla',\n",
       " '▁nhưng',\n",
       " '▁rất',\n",
       " '▁tiếc',\n",
       " '▁đều',\n",
       " '▁rơi',\n",
       " '▁vào',\n",
       " '▁thế',\n",
       " '▁việt',\n",
       " '▁vị',\n",
       " '.',\n",
       " '▁Tuy',\n",
       " '▁nhiên',\n",
       " ',',\n",
       " '▁chỉ',\n",
       " '▁trong',\n",
       " '▁vòng',\n",
       " '▁ít',\n",
       " '▁phút',\n",
       " '▁từ',\n",
       " '▁phút',\n",
       " '▁82',\n",
       " '▁đến',\n",
       " '▁88',\n",
       " ',',\n",
       " '▁các',\n",
       " '▁khá',\n",
       " 'n',\n",
       " '▁giả',\n",
       " '▁có',\n",
       " '▁mặt',\n",
       " '▁trên',\n",
       " '▁sân',\n",
       " '▁Olimp',\n",
       " 'ic',\n",
       " '▁Llu',\n",
       " 'is',\n",
       " '▁Company',\n",
       " 's',\n",
       " '▁đã',\n",
       " '▁được',\n",
       " '▁chứng',\n",
       " '▁kiến',\n",
       " '▁tới',\n",
       " '▁3',\n",
       " '▁bàn',\n",
       " '▁thắng',\n",
       " '.',\n",
       " '▁Cầu',\n",
       " '▁thủ',\n",
       " '▁vào',\n",
       " '▁sân',\n",
       " '▁thay',\n",
       " '▁người',\n",
       " '▁bên',\n",
       " '▁phía',\n",
       " '▁Barcelona',\n",
       " '▁là',\n",
       " '▁Torre',\n",
       " '▁lập',\n",
       " '▁cú',\n",
       " '▁đ',\n",
       " 'úp',\n",
       " ',',\n",
       " '▁xen',\n",
       " '▁giữa',\n",
       " '▁là',\n",
       " '▁bàn',\n",
       " '▁thắng',\n",
       " '▁danh',\n",
       " '▁dự',\n",
       " '▁của',\n",
       " '▁I',\n",
       " 'du',\n",
       " 'mbo',\n",
       " '▁bên',\n",
       " '▁phía',\n",
       " '▁Sevilla',\n",
       " '.',\n",
       " '▁Chung',\n",
       " '▁cuộc',\n",
       " ',',\n",
       " '▁Barca',\n",
       " '▁thắng',\n",
       " '▁Se',\n",
       " 'vil',\n",
       " 'al',\n",
       " '▁với',\n",
       " '▁tỷ',\n",
       " '▁số',\n",
       " '▁',\n",
       " '5-1',\n",
       " '.',\n",
       " '▁Như',\n",
       " '▁vậy',\n",
       " ',',\n",
       " '▁đoàn',\n",
       " '▁quân',\n",
       " '▁của',\n",
       " '▁H',\n",
       " 'LV',\n",
       " '▁Hans',\n",
       " 'i',\n",
       " '▁F',\n",
       " 'lick',\n",
       " '▁củ',\n",
       " 'ng',\n",
       " '▁cố',\n",
       " '▁vị',\n",
       " '▁trí',\n",
       " '▁dẫn',\n",
       " '▁đầu',\n",
       " '▁trên',\n",
       " '▁bảng',\n",
       " '▁xếp',\n",
       " '▁hạng',\n",
       " '▁La',\n",
       " '▁Liga',\n",
       " ',',\n",
       " '▁duy',\n",
       " '▁trì',\n",
       " '▁khoảng',\n",
       " '▁cách',\n",
       " '▁3',\n",
       " '▁điểm',\n",
       " '▁với',\n",
       " '▁đại',\n",
       " '▁k',\n",
       " 'ình',\n",
       " '▁địch',\n",
       " '▁Real',\n",
       " '▁Madrid',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = df['content'][0]\n",
    "tokenized_input = tokenizer(example)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [0, 1, 2] <-> [O, B, I]\n",
    "\n",
    "def align_labels(text_tokens, tag_tokens):\n",
    "\tlabels = [0] * len(text_tokens)\n",
    "\tfor tag in tag_tokens:\n",
    "\t\ttag_len = len(tag)\n",
    "\t\tfor i in range(len(text_tokens) - tag_len + 1):\n",
    "\t\t\tif text_tokens[i:i + tag_len] == tag:\n",
    "\t\t\t\tlabels[i] = 1  # Beginning of keyword\n",
    "\t\t\t\tfor j in range(1, tag_len):\n",
    "\t\t\t\t\tlabels[i + j] = 2  # Inside keyword\n",
    "\t\t\t\tbreak  # Move to the next tag once a match is found\n",
    "\treturn labels\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(text, tags):\n",
    "\ttokenized_input = tokenizer(text, truncation=True, padding='max_length', max_length=512)\n",
    "\ttext_tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\ttag_tokens = [tokenizer.tokenize(tag) for tag in tags]\n",
    "\tlabels = align_labels(text_tokens, tag_tokens)\n",
    "\treturn tokenized_input[\"input_ids\"], tokenized_input[\"attention_mask\"], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 124621, 2249, 48581, 30851, 4, 5755, 13596...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 20255, 3378, 2467, 2249, 10515, 5034, 3122...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 67954, 11181, 135622, 3179, 4417, 166, 306...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 67954, 30851, 58403, 21840, 2368, 3063, 70...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 67954, 11181, 135622, 9006, 67, 10895, 352...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36195</th>\n",
       "      <td>[0, 42812, 611, 23538, 4, 2251, 8215, 142, 175...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36196</th>\n",
       "      <td>[0, 15, 18, 56906, 3063, 4317, 50258, 4, 9611,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36197</th>\n",
       "      <td>[0, 40797, 46331, 9814, 8735, 44980, 313, 5707...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 1, 2, 2, 0, 0, 1, 2, 2, 2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36198</th>\n",
       "      <td>[0, 9211, 27088, 6884, 29225, 52, 249968, 449,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36199</th>\n",
       "      <td>[0, 19491, 7211, 24581, 16859, 2931, 4, 38356,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  \\\n",
       "0      [0, 124621, 2249, 48581, 30851, 4, 5755, 13596...   \n",
       "1      [0, 20255, 3378, 2467, 2249, 10515, 5034, 3122...   \n",
       "2      [0, 67954, 11181, 135622, 3179, 4417, 166, 306...   \n",
       "3      [0, 67954, 30851, 58403, 21840, 2368, 3063, 70...   \n",
       "4      [0, 67954, 11181, 135622, 9006, 67, 10895, 352...   \n",
       "...                                                  ...   \n",
       "36195  [0, 42812, 611, 23538, 4, 2251, 8215, 142, 175...   \n",
       "36196  [0, 15, 18, 56906, 3063, 4317, 50258, 4, 9611,...   \n",
       "36197  [0, 40797, 46331, 9814, 8735, 44980, 313, 5707...   \n",
       "36198  [0, 9211, 27088, 6884, 29225, 52, 249968, 449,...   \n",
       "36199  [0, 19491, 7211, 24581, 16859, 2931, 4, 38356,...   \n",
       "\n",
       "                                                       1  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                  ...   \n",
       "36195  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "36196  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "36197  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "36198  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "36199  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                       2  \n",
       "0      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [0, 0, 0, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "36195  [0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, ...  \n",
       "36196  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "36197  [0, 0, 0, 1, 2, 1, 2, 2, 0, 0, 1, 2, 2, 2, 0, ...  \n",
       "36198  [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, ...  \n",
       "36199  [0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 2, ...  \n",
       "\n",
       "[36200 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df = df.apply(lambda x: tokenize_and_align_labels(x[\"content\"], x[\"tags\"].split(\",\")), axis=1, result_type=\"expand\")\n",
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 124621, 2249, 48581, 30851, 4, 5755, 13596...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 20255, 3378, 2467, 2249, 10515, 5034, 3122...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 67954, 11181, 135622, 3179, 4417, 166, 306...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 67954, 30851, 58403, 21840, 2368, 3063, 70...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 67954, 11181, 135622, 9006, 67, 10895, 352...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36195</th>\n",
       "      <td>[0, 42812, 611, 23538, 4, 2251, 8215, 142, 175...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36196</th>\n",
       "      <td>[0, 15, 18, 56906, 3063, 4317, 50258, 4, 9611,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36197</th>\n",
       "      <td>[0, 40797, 46331, 9814, 8735, 44980, 313, 5707...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 1, 2, 2, 0, 0, 1, 2, 2, 2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36198</th>\n",
       "      <td>[0, 9211, 27088, 6884, 29225, 52, 249968, 449,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36199</th>\n",
       "      <td>[0, 19491, 7211, 24581, 16859, 2931, 4, 38356,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input_ids  \\\n",
       "0      [0, 124621, 2249, 48581, 30851, 4, 5755, 13596...   \n",
       "1      [0, 20255, 3378, 2467, 2249, 10515, 5034, 3122...   \n",
       "2      [0, 67954, 11181, 135622, 3179, 4417, 166, 306...   \n",
       "3      [0, 67954, 30851, 58403, 21840, 2368, 3063, 70...   \n",
       "4      [0, 67954, 11181, 135622, 9006, 67, 10895, 352...   \n",
       "...                                                  ...   \n",
       "36195  [0, 42812, 611, 23538, 4, 2251, 8215, 142, 175...   \n",
       "36196  [0, 15, 18, 56906, 3063, 4317, 50258, 4, 9611,...   \n",
       "36197  [0, 40797, 46331, 9814, 8735, 44980, 313, 5707...   \n",
       "36198  [0, 9211, 27088, 6884, 29225, 52, 249968, 449,...   \n",
       "36199  [0, 19491, 7211, 24581, 16859, 2931, 4, 38356,...   \n",
       "\n",
       "                                          attention_mask  \\\n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                  ...   \n",
       "36195  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "36196  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "36197  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "36198  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "36199  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                  labels  \n",
       "0      [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2      [0, 0, 0, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, ...  \n",
       "3      [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                  ...  \n",
       "36195  [0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, ...  \n",
       "36196  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "36197  [0, 0, 0, 1, 2, 1, 2, 2, 0, 0, 1, 2, 2, 2, 0, ...  \n",
       "36198  [0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, ...  \n",
       "36199  [0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 2, ...  \n",
       "\n",
       "[36200 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df.columns = ['input_ids', 'attention_mask', 'labels']\n",
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open(DATA_PATH + \"tokenized_df_with_attention.pkl\", \"wb\")\n",
    "pickle.dump(tokenized_df, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "label_list = [\"O\", \"B\", \"I\"]\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(\n",
    "        predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"O\", 1: \"B\", 2: \"I\"}\n",
    "label2id = {\"O\": 0, \"B\": 1, \"I\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=len(label_list), id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_wnut_model\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=4,\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    gradient_checkpointing=True,\n",
    "    dataloader_pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2417/2035193246.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9000' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9000/9000 2:22:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.128300</td>\n",
       "      <td>0.123121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.113385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.111639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.119230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9000, training_loss=0.10822826258341471, metrics={'train_runtime': 8533.5185, 'train_samples_per_second': 4.219, 'train_steps_per_second': 1.055, 'total_flos': 9406768287744000.0, 'train_loss': 0.10822826258341471, 'epoch': 4.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Take 10000 random samples for training and evaluation\n",
    "tokenized_df = tokenized_df.sample(10000, random_state=42)\n",
    "\n",
    "train_df, eval_df = train_test_split(tokenized_df, test_size=0.1)\n",
    "\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model(\"./xlm-roberta-keywordtagger-v2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xal4food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
